{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Tweets from Twitter re. COVID</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- df does not include \"since_date\" & \"until_date\" \n",
    "\n",
    "- https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1\n",
    "- https://github.com/Etanangc8/TwitterBot/blob/master/TwitterScraper/GetOldTweets3_Twitter_Scraper.ipynb\n",
    "- https://github.com/Mottl/GetOldTweets3\n",
    "- https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GetOldTweets3\n",
      "  Downloading GetOldTweets3-0.0.11-py3-none-any.whl (13 kB)\n",
      "Collecting pyquery>=1.2.10\n",
      "  Downloading pyquery-1.4.1-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /Users/bibor/opt/anaconda3/lib/python3.7/site-packages (from GetOldTweets3) (4.5.0)\n",
      "Collecting cssselect>0.7.9\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: cssselect, pyquery, GetOldTweets3\n",
      "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 pyquery-1.4.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to request tweets from a state\n",
    "\n",
    "def tweets_by_states(state, text_query, since_date, until_date, count):\n",
    "     # Creation of query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query)\\\n",
    "                    .setSince(since_date).setUntil(until_date).setMaxTweets(count)\\\n",
    "                    .setTopTweets(True).setNear(state)\n",
    "    \n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    \n",
    "    # Creating list of chosen tweet data\n",
    "    text_tweets = [[tweet.date, tweet.text] for tweet in tweets]    \n",
    "    \n",
    "     # Creating dataframe from tweets\n",
    "    tweet_df = pd.DataFrame(text_tweets, columns = ['date', 'text'])\n",
    "    \n",
    "    # return tweet dataframe\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of states\n",
    "\n",
    "states = [\n",
    "        'Alabama',\n",
    "        'Alaska',\n",
    "        'Arizona',\n",
    "        'Arkansas',\n",
    "        'California',\n",
    "        'Colorado',\n",
    "        'Connecticut',\n",
    "        'DC',\n",
    "        'Delaware',\n",
    "        'Florida',\n",
    "        'Georgia',\n",
    "        'Hawaii',\n",
    "        'Idaho',\n",
    "        'Illinois',\n",
    "        'Indiana',\n",
    "        'Iowa',\n",
    "        'Kansas',\n",
    "        'Kentucky',\n",
    "        'Louisiana',\n",
    "        'Maine',\n",
    "        'Maryland',\n",
    "        'Massachusetts',\n",
    "        'Michigan',\n",
    "        'Minnesota',\n",
    "        'Mississippi',\n",
    "        'Missouri',\n",
    "        'Montana',\n",
    "        'Nebraska',\n",
    "        'Nevada',\n",
    "        'New Hampshire',\n",
    "        'New Jersey',\n",
    "        'New Mexico',\n",
    "        'New York',\n",
    "        'North Carolina',\n",
    "        'North Dakota',\n",
    "        'Ohio',\n",
    "        'Oklahoma',\n",
    "        'Oregon',\n",
    "        'Pennsylvania',\n",
    "        'Rhode Island',\n",
    "        'South Carolina',\n",
    "        'South Dakota',\n",
    "        'Tennessee',\n",
    "        'Texas',\n",
    "        'Utah',\n",
    "        'Vermont',\n",
    "        'Virginia',\n",
    "        'Washington',\n",
    "        'West Virginia',\n",
    "        'Wisconsin',\n",
    "        'Wyoming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulling tweets\n",
    "\n",
    "**\"social distancing\", \"executive orders\", \"emergency declaration\", \"election postpone\", \"restaurant closure\"**\n",
    "\n",
    "Febr. 1, 2020 - Febr. 29, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama 1\n",
      "Alaska 2\n",
      "Arizona 3\n",
      "Arkansas 4\n",
      "California 5\n",
      "Colorado 6\n",
      "Connecticut 7\n",
      "DC 8\n",
      "Delaware 9\n",
      "Florida 10\n",
      "Georgia 11\n",
      "Hawaii 12\n",
      "Idaho 13\n",
      "Illinois 14\n",
      "Indiana 15\n",
      "Iowa 16\n",
      "Kansas 17\n",
      "Kentucky 18\n",
      "Louisiana 19\n",
      "Maine 20\n",
      "Maryland 21\n",
      "Massachusetts 22\n",
      "Michigan 23\n",
      "Minnesota 24\n",
      "Mississippi 25\n",
      "Missouri 26\n",
      "Montana 27\n",
      "Nebraska 28\n",
      "Nevada 29\n",
      "New Hampshire 30\n",
      "New Jersey 31\n",
      "New Mexico 32\n",
      "New York 33\n",
      "North Carolina 34\n",
      "North Dakota 35\n",
      "Ohio 36\n",
      "Oklahoma 37\n",
      "Oregon 38\n",
      "Pennsylvania 39\n",
      "Rhode Island 40\n",
      "South Carolina 41\n",
      "South Dakota 42\n",
      "Tennessee 43\n",
      "Texas 44\n",
      "Utah 45\n",
      "Vermont 46\n",
      "Virginia 47\n",
      "Washington 48\n",
      "West Virginia 49\n",
      "Wisconsin 50\n",
      "Wyoming 51\n"
     ]
    }
   ],
   "source": [
    "# Creating empty dataframe\n",
    "tweet_df = pd.DataFrame(columns = ['date', 'text', 'state', 'query_term'])\n",
    "\n",
    "# Instantiating counter\n",
    "counter = 0\n",
    "\n",
    "# creating for loop to iterate through states\n",
    "# pull tweets for each state\n",
    "for state in states:\n",
    "    counter += 1\n",
    "    \n",
    "    # parameters of query\n",
    "    text_query = 'restaurant closure'\n",
    "    since_date = '2020-02-01'\n",
    "    until_date = '2020-02-29'\n",
    "    count = 2000\n",
    "    \n",
    "    # pull tweets from twitter\n",
    "    tweets = tweets_by_states(state, text_query, since_date, until_date, count)\n",
    "    # add state name to 'state' column\n",
    "    tweets['state'] = state\n",
    "    # add query term to 'query_term' column\n",
    "    tweets['query_term'] = text_query\n",
    "    \n",
    "    # create dataframe from tweets\n",
    "    tweet_df = tweet_df.append(tweets)\n",
    "#     print(tweet_df)\n",
    "    \n",
    "    # export tweets to csv file\n",
    "    tweet_df.to_csv('../data/restaurantClosure_February.csv', index=False)\n",
    "    \n",
    "    print(state, counter)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "df = pd.read_csv('../data/restaurantClosure_February.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"social distancing\", \"executive orders\", \"emergency declaration\", \"election postpone\", \"restaurant closure\"**\n",
    "\n",
    "March. 1, 2020 - March. 31, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama 1\n",
      "Alaska 2\n",
      "Arizona 3\n",
      "Arkansas 4\n",
      "California 5\n",
      "Colorado 6\n",
      "Connecticut 7\n",
      "DC 8\n",
      "Delaware 9\n",
      "Florida 10\n",
      "Georgia 11\n",
      "Hawaii 12\n",
      "Idaho 13\n",
      "Illinois 14\n",
      "Indiana 15\n",
      "Iowa 16\n",
      "Kansas 17\n",
      "Kentucky 18\n",
      "Louisiana 19\n",
      "Maine 20\n",
      "Maryland 21\n",
      "Massachusetts 22\n",
      "Michigan 23\n",
      "Minnesota 24\n",
      "Mississippi 25\n",
      "Missouri 26\n",
      "Montana 27\n",
      "Nebraska 28\n",
      "Nevada 29\n",
      "New Hampshire 30\n",
      "New Jersey 31\n",
      "New Mexico 32\n",
      "New York 33\n",
      "North Carolina 34\n",
      "North Dakota 35\n",
      "Ohio 36\n",
      "Oklahoma 37\n",
      "Oregon 38\n",
      "Pennsylvania 39\n",
      "Rhode Island 40\n",
      "South Carolina 41\n",
      "South Dakota 42\n",
      "Tennessee 43\n",
      "Texas 44\n",
      "Utah 45\n",
      "Vermont 46\n",
      "Virginia 47\n",
      "Washington 48\n",
      "West Virginia 49\n",
      "Wisconsin 50\n",
      "Wyoming 51\n"
     ]
    }
   ],
   "source": [
    "# Creating empty dataframe\n",
    "tweet_df = pd.DataFrame(columns = ['date', 'text', 'state', 'query_term'])\n",
    "\n",
    "# Instantiating counter\n",
    "counter = 0\n",
    "\n",
    "# creating for loop to iterate through states\n",
    "# pull tweets for each state\n",
    "for state in states:\n",
    "    counter += 1\n",
    "    \n",
    "    # parameters of query\n",
    "    text_query = 'restaurant closure'\n",
    "    since_date = '2020-03-01'\n",
    "    until_date = '2020-03-31'\n",
    "    count = 0\n",
    "    \n",
    "    # pull tweets from twitter\n",
    "    tweets = tweets_by_states(state, text_query, since_date, until_date, count)\n",
    "    # add state name to 'state' column\n",
    "    tweets['state'] = state\n",
    "    # add query term to 'query_term' column\n",
    "    tweets['query_term'] = text_query\n",
    "    \n",
    "    # create dataframe from tweets\n",
    "    tweet_df = tweet_df.append(tweets)\n",
    "#     print(tweet_df)\n",
    "    \n",
    "    # export tweets to csv file\n",
    "    tweet_df.to_csv('../data/restaurantClosure_March.csv', index=False)\n",
    "    \n",
    "    print(state, counter)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "df = pd.read_csv('../data/restaurantClosure_March.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"social distancing\", \"executive orders\", \"emergency declaration\", \"election postpone\", \"restaurant closure\"**\n",
    "\n",
    "April. 1, 2020 - April. 30, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama 1\n",
      "Alaska 2\n",
      "Arizona 3\n",
      "Arkansas 4\n",
      "California 5\n",
      "Colorado 6\n",
      "Connecticut 7\n",
      "DC 8\n",
      "Delaware 9\n",
      "Florida 10\n",
      "Georgia 11\n",
      "Hawaii 12\n",
      "Idaho 13\n",
      "Illinois 14\n",
      "Indiana 15\n",
      "Iowa 16\n",
      "Kansas 17\n",
      "Kentucky 18\n",
      "Louisiana 19\n",
      "Maine 20\n",
      "Maryland 21\n",
      "Massachusetts 22\n",
      "Michigan 23\n",
      "Minnesota 24\n",
      "Mississippi 25\n",
      "Missouri 26\n",
      "Montana 27\n",
      "Nebraska 28\n",
      "Nevada 29\n",
      "New Hampshire 30\n",
      "New Jersey 31\n",
      "New Mexico 32\n",
      "New York 33\n",
      "North Carolina 34\n",
      "North Dakota 35\n",
      "Ohio 36\n",
      "Oklahoma 37\n",
      "Oregon 38\n",
      "Pennsylvania 39\n",
      "Rhode Island 40\n",
      "South Carolina 41\n",
      "South Dakota 42\n",
      "Tennessee 43\n",
      "Texas 44\n",
      "Utah 45\n",
      "Vermont 46\n",
      "Virginia 47\n",
      "Washington 48\n",
      "West Virginia 49\n",
      "Wisconsin 50\n",
      "Wyoming 51\n"
     ]
    }
   ],
   "source": [
    "# Creating empty dataframe\n",
    "tweet_df = pd.DataFrame(columns = ['date', 'text', 'state', 'query_term'])\n",
    "\n",
    "# Instantiating counter\n",
    "counter = 0\n",
    "\n",
    "# creating for loop to iterate through states\n",
    "# pull tweets for each state\n",
    "for state in states:\n",
    "    counter += 1\n",
    "    \n",
    "    # parameters of query\n",
    "    text_query = 'restaurant closure'\n",
    "    since_date = '2020-04-01'\n",
    "    until_date = '2020-04-30'\n",
    "    count = 0 # get everything\n",
    "    \n",
    "    # pull tweets from twitter\n",
    "    tweets = tweets_by_states(state, text_query, since_date, until_date, count)\n",
    "    # add state name to 'state' column\n",
    "    tweets['state'] = state\n",
    "    # add query term to 'query_term' column\n",
    "    tweets['query_term'] = text_query\n",
    "    \n",
    "    # create dataframe from tweets\n",
    "    tweet_df = tweet_df.append(tweets)\n",
    "#     print(tweet_df)\n",
    "    \n",
    "    # export tweets to csv file\n",
    "    tweet_df.to_csv('../data/restaurantClosure_April.csv', index=False)\n",
    "    \n",
    "    print(state, counter)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "df = pd.read_csv('../data/restaurantClosure_April.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"social distancing\", \"executive orders\", \"emergency declaration\", \"election postpone\", \"restaurant closure\"**\n",
    "\n",
    "May. 1, 2020 - May. 6, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama 1\n",
      "Alaska 2\n",
      "Arizona 3\n",
      "Arkansas 4\n",
      "California 5\n",
      "Colorado 6\n",
      "Connecticut 7\n",
      "DC 8\n",
      "Delaware 9\n",
      "Florida 10\n",
      "Georgia 11\n",
      "Hawaii 12\n",
      "Idaho 13\n",
      "Illinois 14\n",
      "Indiana 15\n",
      "Iowa 16\n",
      "Kansas 17\n",
      "Kentucky 18\n",
      "Louisiana 19\n",
      "Maine 20\n",
      "Maryland 21\n",
      "Massachusetts 22\n",
      "Michigan 23\n",
      "Minnesota 24\n",
      "Mississippi 25\n",
      "Missouri 26\n",
      "Montana 27\n",
      "Nebraska 28\n",
      "Nevada 29\n",
      "New Hampshire 30\n",
      "New Jersey 31\n",
      "New Mexico 32\n",
      "New York 33\n",
      "North Carolina 34\n",
      "North Dakota 35\n",
      "Ohio 36\n",
      "Oklahoma 37\n",
      "Oregon 38\n",
      "Pennsylvania 39\n",
      "Rhode Island 40\n",
      "South Carolina 41\n",
      "South Dakota 42\n",
      "Tennessee 43\n",
      "Texas 44\n",
      "Utah 45\n",
      "Vermont 46\n",
      "Virginia 47\n",
      "Washington 48\n",
      "West Virginia 49\n",
      "Wisconsin 50\n",
      "Wyoming 51\n"
     ]
    }
   ],
   "source": [
    "# Creating empty dataframe\n",
    "tweet_df = pd.DataFrame(columns = ['date', 'text', 'state', 'query_term'])\n",
    "\n",
    "# Instantiating counter\n",
    "counter = 0\n",
    "\n",
    "# creating for loop to iterate through states\n",
    "# pull tweets for each state\n",
    "for state in states:\n",
    "    counter += 1\n",
    "    \n",
    "    # parameters of query\n",
    "    text_query = 'restaurant closure'\n",
    "    since_date = '2020-05-01'\n",
    "    until_date = '2020-05-06'\n",
    "    count = 0 # get everything\n",
    "    \n",
    "    # pull tweets from twitter\n",
    "    tweets = tweets_by_states(state, text_query, since_date, until_date, count)\n",
    "    # add state name to 'state' column\n",
    "    tweets['state'] = state\n",
    "    # add query term to 'query_term' column\n",
    "    tweets['query_term'] = text_query\n",
    "    \n",
    "    # create dataframe from tweets\n",
    "    tweet_df = tweet_df.append(tweets)\n",
    "#     print(tweet_df)\n",
    "    \n",
    "    # export tweets to csv file\n",
    "    tweet_df.to_csv('../data/restaurantClosure_May.csv', index=False)\n",
    "    \n",
    "    print(state, counter)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "df = pd.read_csv('../data/restaurantClosure_May.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"social distancing\", \"executive orders\", \"emergency declaration\", \"election postpone\", \"restaurant closure\"**\n",
    "\n",
    "May. 7, 2020 - May. 10, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of text queries\n",
    "\n",
    "text_queries = ['social distancing', 'executive orders', 'emergency declaration', \n",
    "                'election postpone', 'restaurant closure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama 1\n",
      "Alaska 2\n",
      "Arizona 3\n",
      "Arkansas 4\n",
      "California 5\n",
      "Colorado 6\n",
      "Connecticut 7\n",
      "DC 8\n",
      "Delaware 9\n",
      "Florida 10\n",
      "Georgia 11\n",
      "Hawaii 12\n",
      "Idaho 13\n",
      "Illinois 14\n",
      "Indiana 15\n",
      "Iowa 16\n",
      "Kansas 17\n",
      "Kentucky 18\n",
      "Louisiana 19\n",
      "Maine 20\n",
      "Maryland 21\n",
      "Massachusetts 22\n",
      "Michigan 23\n",
      "Minnesota 24\n",
      "Mississippi 25\n",
      "Missouri 26\n",
      "Montana 27\n",
      "Nebraska 28\n",
      "Nevada 29\n",
      "New Hampshire 30\n",
      "New Jersey 31\n",
      "New Mexico 32\n",
      "New York 33\n",
      "North Carolina 34\n",
      "North Dakota 35\n",
      "Ohio 36\n",
      "Oklahoma 37\n",
      "Oregon 38\n",
      "Pennsylvania 39\n",
      "Rhode Island 40\n",
      "South Carolina 41\n",
      "South Dakota 42\n",
      "Tennessee 43\n",
      "Texas 44\n",
      "Utah 45\n",
      "Vermont 46\n",
      "Virginia 47\n",
      "Washington 48\n",
      "West Virginia 49\n",
      "Wisconsin 50\n",
      "Wyoming 51\n"
     ]
    }
   ],
   "source": [
    "# Creating empty dataframe\n",
    "tweet_df = pd.DataFrame(columns = ['date', 'text', 'state', 'query_term'])\n",
    "\n",
    "# Creating empty list of tweets from states\n",
    "tweets_state = []\n",
    "\n",
    "# Instantiating counter\n",
    "counter = 0\n",
    "\n",
    "# creating for loop to iterate through states\n",
    "# pull tweets for each state\n",
    "for state in states:\n",
    "    counter += 1\n",
    "    for text_query in text_queries:\n",
    "        # parameters of query\n",
    "        since_date = '2020-05-06'\n",
    "        until_date = '2020-05-10'\n",
    "        count = 0 # get everything\n",
    "    \n",
    "        # pull tweets from twitter\n",
    "        tweets = tweets_by_states(state, text_query, since_date, until_date, count)\n",
    "        # add state name to 'state' column\n",
    "        tweets['state'] = state\n",
    "        # add query term to 'query_term' column\n",
    "        tweets['query_term'] = text_query\n",
    "        \n",
    "        # add tweets to tweets_state list\n",
    "        tweets_state.append(tweets)\n",
    "\n",
    "    # add tweets from each state to tweet dataframe\n",
    "    tweet_df = tweet_df.append(tweets_state)\n",
    "    #   print(tweet_df)\n",
    "    \n",
    "    # export tweets to csv file\n",
    "    tweet_df.to_csv('../data/May6_10.csv', index=False)\n",
    "    \n",
    "    print(state, counter)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "df = pd.read_csv('../data/May6_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171154, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tweets\n",
    "# read in data\n",
    "data = pd.concat([\n",
    "    pd.read_csv('../data/busi_clo_April-byState.csv'),\n",
    "    pd.read_csv('../data/busi_clo_March-byState.csv'),\n",
    "    pd.read_csv('../data/busi_clo_until-May_06-byState.csv'),\n",
    "    pd.read_csv('../data/coronavirus_April-byState.csv'),\n",
    "    pd.read_csv('../data/coronavirus_Feb_byState.csv'),\n",
    "    pd.read_csv('../data/coronavirus_March-byState.csv'),\n",
    "    pd.read_csv('../data/coronavirus_until-May_06-byState.csv'),\n",
    "    pd.read_csv('../data/covid_April-byState.csv'),\n",
    "    pd.read_csv('../data/covid_Feb-byState.csv'),\n",
    "    pd.read_csv('../data/covid_March-byState.csv'),\n",
    "    pd.read_csv('../data/covid_until-May-06-byState.csv'),\n",
    "    pd.read_csv('../data/electionPostpone_April.csv'),\n",
    "    pd.read_csv('../data/electionPostpone_February.csv'),\n",
    "    pd.read_csv('../data/electionPostpone_March.csv'),\n",
    "    pd.read_csv('../data/electionPostpone_May.csv'),\n",
    "    pd.read_csv('../data/emergencyDeclaration_April.csv'),\n",
    "    pd.read_csv('../data/emergencyDeclaration_February.csv'),\n",
    "    pd.read_csv('../data/emergencyDeclaration_March.csv'),\n",
    "    pd.read_csv('../data/emergencyDeclaration_May.csv'),\n",
    "    pd.read_csv('../data/executiveOrders_April.csv'),\n",
    "    pd.read_csv('../data/executiveOrders_February.csv'),\n",
    "    pd.read_csv('../data/executiveOrders_March.csv'),\n",
    "    pd.read_csv('../data/executiveOrders_May.csv'),\n",
    "    pd.read_csv('../data/man_quar_April-byState.csv'),\n",
    "    pd.read_csv('../data/man_quar_until-May_06-byState.csv'),\n",
    "    pd.read_csv('../data/man-quar_March-byState.csv'),\n",
    "    pd.read_csv('../data/May6_10.csv'),\n",
    "    pd.read_csv('../data/restaurantClosure_April.csv'),\n",
    "    pd.read_csv('../data/restaurantClosure_February.csv'),\n",
    "    pd.read_csv('../data/restaurantClosure_March.csv'),\n",
    "    pd.read_csv('../data/restaurantClosure_May.csv'),\n",
    "    pd.read_csv('../data/sch_clo_April-byState.csv'),\n",
    "    pd.read_csv('../data/sch_clo_March-byState.csv'),\n",
    "    pd.read_csv('../data/sch_clo_until-May_06-byState.csv'),\n",
    "    pd.read_csv('../data/shel_in_pl_April-byState.csv'),\n",
    "    pd.read_csv('../data/shel_in_pl_March-byState.csv'),\n",
    "    pd.read_csv('../data/shel_in_pl_until-May_06-byState.csv'),\n",
    "    pd.read_csv('../data/socialDistancing_April.csv'),\n",
    "    pd.read_csv('../data/socialDistancing_February.csv'),\n",
    "    pd.read_csv('../data/socialDistancing_March.csv'),\n",
    "    pd.read_csv('../data/socialDistancing_May.csv')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>query_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-24 21:59:42+00:00</td>\n",
       "      <td>The economy will collapse in the long term if ...</td>\n",
       "      <td>DC</td>\n",
       "      <td>business closures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-23 21:28:12+00:00</td>\n",
       "      <td>Classic counsel on cover letters! Covid-19 and...</td>\n",
       "      <td>DC</td>\n",
       "      <td>business closures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-17 01:01:43+00:00</td>\n",
       "      <td>I'm guessing that would violate the mayor's no...</td>\n",
       "      <td>DC</td>\n",
       "      <td>business closures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-16 18:19:35+00:00</td>\n",
       "      <td>Ok, why did this take so long...and yet mandat...</td>\n",
       "      <td>DC</td>\n",
       "      <td>business closures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-16 01:53:41+00:00</td>\n",
       "      <td>Explain exactly how government-forced business...</td>\n",
       "      <td>DC</td>\n",
       "      <td>business closures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "0  2020-04-24 21:59:42+00:00   \n",
       "1  2020-04-23 21:28:12+00:00   \n",
       "2  2020-04-17 01:01:43+00:00   \n",
       "3  2020-04-16 18:19:35+00:00   \n",
       "4  2020-04-16 01:53:41+00:00   \n",
       "\n",
       "                                                text state         query_term  \n",
       "0  The economy will collapse in the long term if ...    DC  business closures  \n",
       "1  Classic counsel on cover letters! Covid-19 and...    DC  business closures  \n",
       "2  I'm guessing that would violate the mayor's no...    DC  business closures  \n",
       "3  Ok, why did this take so long...and yet mandat...    DC  business closures  \n",
       "4  Explain exactly how government-forced business...    DC  business closures  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216443, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export combined dataset\n",
    "\n",
    "data.to_csv('../cleandata/tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../cleandata/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216443, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
